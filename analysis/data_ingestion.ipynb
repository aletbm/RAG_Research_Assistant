{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb2a812",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a820dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8bcf05",
   "metadata": {},
   "source": [
    "## arXiv API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af7fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5b4f72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 39)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_categories = {\n",
    "    \"cs.LG\": \"Machine Learning\",\n",
    "    \"cs.CV\": \"Computer Vision and Pattern Recognition\",\n",
    "    \"cs.CL\": \"Computation and Language\",\n",
    "    \"cs.AI\": \"Artificial Intelligence\",\n",
    "    \"stat.ML\": \"Statistics\",\n",
    "    \"eess.IV\": \"Electrical Engineering and Systems Science\",\n",
    "    \"cs.RO\": \"Robotics\",\n",
    "    \"cs.NE\": \"Neural and Evolutionary Computing\",\n",
    "    #\"cs.HC\": \"Human-Computer Interaction\",\n",
    "    #\"cs.DS\": \"Data Structures and Algorithms\",\n",
    "    #\"cs.CR\": \"Cryptography and Security\",\n",
    "    #\"astro-ph\": \"Astrophysics\",\n",
    "    #\"cond-mat\": \"Condensed Matter\",\n",
    "    #\"hep-ph\": \"High Energy Physics\",\n",
    "    #\"hep-th\": \"High Energy Physics\",\n",
    "    #\"quant-ph\": \"Quantum Physics\",\n",
    "    #\"math-ph\": \"Mathematical Physics\",\n",
    "    #\"gr-qc\": \"General Relativity and Quantum Cosmology\",\n",
    "}\n",
    "\n",
    "trending_keywords = {\n",
    "    \"model_architecture\": [\n",
    "        \"transformer\",\n",
    "        \"BERT\",\n",
    "        \"GPT\",\n",
    "        \"LLaMA\",\n",
    "        \"vision transformer\",\n",
    "        \"ViT\",\n",
    "        \"GNN\",\n",
    "        \"CNN\",\n",
    "        \"RNN\",\n",
    "        \"autoencoder\",\n",
    "        \"variational autoencoder\",\n",
    "        \"attention mechanism\",\n",
    "        \"GAN\"\n",
    "    ],\n",
    "    \"techniques\": [\n",
    "        \"self-supervised learning\",\n",
    "        \"unsupervised learning\",\n",
    "        \"reinforcement learning\",\n",
    "        \"contrastive learning\",\n",
    "        \"few-shot learning\",\n",
    "        \"zero-shot learning\",\n",
    "        \"meta-learning\",\n",
    "        \"transfer learning\",\n",
    "        \"foundation model\",\n",
    "        \"multimodal learning\"\n",
    "    ],\n",
    "    \"applications\": [\n",
    "        \"computer vision\",\n",
    "        \"image classification\",\n",
    "        \"object detection\",\n",
    "        \"segmentation\",\n",
    "        \"NLP\",\n",
    "        \"speech recognition\",\n",
    "        \"ASR\",\n",
    "        \"robotics\",\n",
    "        \"autonomous systems\",\n",
    "        \"bioinformatics\",\n",
    "        \"recommendation system\"\n",
    "    ],\n",
    "    \"content_generation\": [\n",
    "        \"text generation\",\n",
    "        \"image generation\",\n",
    "        \"diffusion model\",\n",
    "        \"LLM\",\n",
    "        \"retrieval augmented generation\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "all_keywords = sum(trending_keywords.values(), [])\n",
    "\n",
    "len(arxiv_categories), len(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf6043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0431ce048ddd4d2cb3565a18b9ea0820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing categories:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae79d1b4242a4f7ca1754f35db651fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing keywords:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26d77cccfa14767969e5144f69ed218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing keywords:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310b520dc5ba48d8a302a6d9d08c6cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing keywords:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510f92c4953b4a8a99210371805bc551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing keywords:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7843572bc24f4990824ec95fdf02c867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing keywords:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47312c972284a0fb7b8e5648c35d0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing keywords:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc33f4101d64ea8b8b7835c639d678e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing keywords:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cbd72679334b34874b9f9c2de6bd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing keywords:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import arxiv\n",
    "from arxiv import UnexpectedEmptyPageError\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "client = arxiv.Client(\n",
    "        page_size=2000,\n",
    "        delay_seconds=10.0,\n",
    "        num_retries=5\n",
    "    )\n",
    "\n",
    "articles = []\n",
    "num_keywords = 2\n",
    "years=7\n",
    "now = datetime.now()\n",
    "start_date = (now - timedelta(days=365*years)).strftime(\"%Y%m%d%H%M\")\n",
    "end_date = now.strftime(\"%Y%m%d%H%M\")\n",
    "categories = arxiv_categories.items()\n",
    "\n",
    "for cat, name in tqdm(categories, total=len(categories), desc=\"Processing categories\"):\n",
    "    for keyword in tqdm(all_keywords, total=len(all_keywords), desc=\"Processing keywords\", leave=False, position=1):\n",
    "        query = f\"cat:{cat} AND ti:\\\"{keyword}\\\" AND submittedDate:[{start_date} TO {end_date}]\"\n",
    "        search = arxiv.Search(query=query, max_results=15000, sort_by=arxiv.SortCriterion.SubmittedDate, sort_order=arxiv.SortOrder.Descending)\n",
    "        try:\n",
    "            for result in client.results(search):\n",
    "                articles.append({\n",
    "                    \"title\": result.title,\n",
    "                    \"categories\": result.categories,\n",
    "                    \"keyword\": keyword,\n",
    "                    \"abstract\": result.summary,\n",
    "                    \"authors\": [author.name for author in result.authors],\n",
    "                    \"url\": result.entry_id,\n",
    "                    \"published\": result.published,\n",
    "                    \"year\": result.published.year\n",
    "                })\n",
    "        except UnexpectedEmptyPageError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6652628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30645"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510218d",
   "metadata": {},
   "source": [
    "## OpenAlex API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ed4c27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyalex python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18cf622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyalex import config\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "config.email = os.getenv(\"EMAIL\")\n",
    "config.max_retries = 5\n",
    "config.retry_backoff_factor = 0.5\n",
    "config.retry_http_codes = [429, 500, 503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b622cbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2521d8d9084b4b26a61f646aa9e3791e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyalex import Topics, Works\n",
    "\n",
    "articles_oa = []\n",
    "\n",
    "for category, name in tqdm(arxiv_categories.items()):\n",
    "\n",
    "    topics = Topics().search(name).get()\n",
    "\n",
    "    for t in topics:\n",
    "        topic_id = t[\"id\"]\n",
    "\n",
    "        if t[\"works_count\"] > 0:\n",
    "            works_generator = Works().filter(\n",
    "                topics={\"id\": [topic_id.split(\"/\")[-1]]},\n",
    "                has_abstract=True\n",
    "            ).paginate(per_page=200)\n",
    "\n",
    "            for i, works_page in enumerate(works_generator):\n",
    "                for w in works_page[:1000]:\n",
    "                    if \"abstract_inverted_index\" in w and w[\"abstract_inverted_index\"]:\n",
    "                        inv_index = w[\"abstract_inverted_index\"]\n",
    "                        max_pos = max(pos for positions in inv_index.values() for pos in positions)\n",
    "                        abstract_words = [None] * (max_pos + 1)\n",
    "\n",
    "                        for word, positions in inv_index.items():\n",
    "                            for pos in positions:\n",
    "                                abstract_words[pos] = word\n",
    "\n",
    "                        abstract_text = \" \".join(w for w in abstract_words if w)\n",
    "                        articles_oa.append({\n",
    "                            \"title\": w[\"display_name\"],\n",
    "                            \"categories\": category,\n",
    "                            \"abstract\": abstract_text,\n",
    "                            \"authors\": [a[\"author\"][\"display_name\"] for a in  w[\"authorships\"]],\n",
    "                            \"url\": w[\"id\"],\n",
    "                            \"published\": w.get(\"publication_date\"),\n",
    "                            \"year\": w.get(\"publication_year\")\n",
    "                        })\n",
    "\n",
    "                    else:\n",
    "                        print(\"Abstract: N/A\")\n",
    "\n",
    "                if i == 5:\n",
    "                    break\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aff918ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108485"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles_oa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1be63",
   "metadata": {},
   "source": [
    "## Lists to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3902ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Structure-Attribute Transformations with Marko...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>Graph domain adaptation has gained significant...</td>\n",
       "      <td>[Zhen Liu, Yongtao Zhang, Shaobo Ren, Yuxin You]</td>\n",
       "      <td>http://arxiv.org/abs/2509.21059v1</td>\n",
       "      <td>2025-09-25 12:09:53+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAIFormer: Multi-Agent Inverted Transformer fo...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>Flight trajectory prediction for multiple airc...</td>\n",
       "      <td>[Seokbin Yoon, Keumjin Lee]</td>\n",
       "      <td>http://arxiv.org/abs/2509.21004v1</td>\n",
       "      <td>2025-09-25 10:59:29+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why Attention Fails: The Degeneration of Trans...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>Transformer-based architectures achieved high ...</td>\n",
       "      <td>[Zida Liang, Jiayi Zhu, Weiqiang Sun]</td>\n",
       "      <td>http://arxiv.org/abs/2509.20942v1</td>\n",
       "      <td>2025-09-25 09:25:51+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FHRFormer: A Self-supervised Transformer Appro...</td>\n",
       "      <td>cs.LG, cs.AI, cs.CE, cs.CV</td>\n",
       "      <td>transformer</td>\n",
       "      <td>Approximately 10\\% of newborns require assista...</td>\n",
       "      <td>[Kjersti Engan, Neel Kanwal, Anita Yeconia, La...</td>\n",
       "      <td>http://arxiv.org/abs/2509.20852v1</td>\n",
       "      <td>2025-09-25 07:40:21+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2I-Diff: fMRI Signal Generation via Time-Freq...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>transformer</td>\n",
       "      <td>Functional Magnetic Resonance Imaging (fMRI) i...</td>\n",
       "      <td>[Hwa Hui Tew, Junn Yong Loo, Yee-Fan Tan, Xiny...</td>\n",
       "      <td>http://arxiv.org/abs/2509.20822v1</td>\n",
       "      <td>2025-09-25 07:08:19+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Structure-Attribute Transformations with Marko...   \n",
       "1  MAIFormer: Multi-Agent Inverted Transformer fo...   \n",
       "2  Why Attention Fails: The Degeneration of Trans...   \n",
       "3  FHRFormer: A Self-supervised Transformer Appro...   \n",
       "4  T2I-Diff: fMRI Signal Generation via Time-Freq...   \n",
       "\n",
       "                   categories      keyword  \\\n",
       "0                       cs.LG  transformer   \n",
       "1                       cs.LG  transformer   \n",
       "2                       cs.LG  transformer   \n",
       "3  cs.LG, cs.AI, cs.CE, cs.CV  transformer   \n",
       "4                       cs.LG  transformer   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Graph domain adaptation has gained significant...   \n",
       "1  Flight trajectory prediction for multiple airc...   \n",
       "2  Transformer-based architectures achieved high ...   \n",
       "3  Approximately 10\\% of newborns require assista...   \n",
       "4  Functional Magnetic Resonance Imaging (fMRI) i...   \n",
       "\n",
       "                                             authors  \\\n",
       "0   [Zhen Liu, Yongtao Zhang, Shaobo Ren, Yuxin You]   \n",
       "1                        [Seokbin Yoon, Keumjin Lee]   \n",
       "2              [Zida Liang, Jiayi Zhu, Weiqiang Sun]   \n",
       "3  [Kjersti Engan, Neel Kanwal, Anita Yeconia, La...   \n",
       "4  [Hwa Hui Tew, Junn Yong Loo, Yee-Fan Tan, Xiny...   \n",
       "\n",
       "                                 url                 published  year  \n",
       "0  http://arxiv.org/abs/2509.21059v1 2025-09-25 12:09:53+00:00  2025  \n",
       "1  http://arxiv.org/abs/2509.21004v1 2025-09-25 10:59:29+00:00  2025  \n",
       "2  http://arxiv.org/abs/2509.20942v1 2025-09-25 09:25:51+00:00  2025  \n",
       "3  http://arxiv.org/abs/2509.20852v1 2025-09-25 07:40:21+00:00  2025  \n",
       "4  http://arxiv.org/abs/2509.20822v1 2025-09-25 07:08:19+00:00  2025  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=articles)\n",
    "df[\"categories\"] = df[\"categories\"].apply(lambda x: \", \".join(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1ea8677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCSF Chimera—A visualization system for explor...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>The design, implementation, and capabilities o...</td>\n",
       "      <td>[Eric F. Pettersen, Thomas D. Goddard, Conrad ...</td>\n",
       "      <td>https://openalex.org/W2132629607</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AutoDock Vina: Improving the speed and accurac...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>AutoDock Vina, a new program for molecular doc...</td>\n",
       "      <td>[Oleg Trott, Arthur J. Olson]</td>\n",
       "      <td>https://openalex.org/W2134967712</td>\n",
       "      <td>2009-06-04</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaussian basis sets for use in correlated mole...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>In the past, basis sets for use in correlated ...</td>\n",
       "      <td>[Thom H. Dunning]</td>\n",
       "      <td>https://openalex.org/W2069006374</td>\n",
       "      <td>1989-01-15</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The M06 suite of density functionals for main ...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>We present two new hybrid meta exchange- corre...</td>\n",
       "      <td>[Yan Zhao, Donald G. Truhlar]</td>\n",
       "      <td>https://openalex.org/W2150697053</td>\n",
       "      <td>2007-07-12</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;i&gt;VESTA 3&lt;/i&gt;for three-dimensional visualizat...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>VESTA is a three-dimensional visualization sys...</td>\n",
       "      <td>[Koichi Momma, Fujio Izumi]</td>\n",
       "      <td>https://openalex.org/W2028056984</td>\n",
       "      <td>2011-10-28</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title categories  \\\n",
       "0  UCSF Chimera—A visualization system for explor...      cs.LG   \n",
       "1  AutoDock Vina: Improving the speed and accurac...      cs.LG   \n",
       "2  Gaussian basis sets for use in correlated mole...      cs.LG   \n",
       "3  The M06 suite of density functionals for main ...      cs.LG   \n",
       "4  <i>VESTA 3</i>for three-dimensional visualizat...      cs.LG   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The design, implementation, and capabilities o...   \n",
       "1  AutoDock Vina, a new program for molecular doc...   \n",
       "2  In the past, basis sets for use in correlated ...   \n",
       "3  We present two new hybrid meta exchange- corre...   \n",
       "4  VESTA is a three-dimensional visualization sys...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [Eric F. Pettersen, Thomas D. Goddard, Conrad ...   \n",
       "1                      [Oleg Trott, Arthur J. Olson]   \n",
       "2                                  [Thom H. Dunning]   \n",
       "3                      [Yan Zhao, Donald G. Truhlar]   \n",
       "4                        [Koichi Momma, Fujio Izumi]   \n",
       "\n",
       "                                url   published  year  \n",
       "0  https://openalex.org/W2132629607  2004-07-01  2004  \n",
       "1  https://openalex.org/W2134967712  2009-06-04  2009  \n",
       "2  https://openalex.org/W2069006374  1989-01-15  1989  \n",
       "3  https://openalex.org/W2150697053  2007-07-12  2007  \n",
       "4  https://openalex.org/W2028056984  2011-10-28  2011  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oa = pd.DataFrame(data=articles_oa)\n",
    "df_oa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a27b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_duplicated = df[df[[\"title\", \"abstract\", \"url\"]].duplicated()].index\n",
    "df.drop(idx_duplicated, axis=0, inplace=True)\n",
    "\n",
    "idx_duplicated = df_oa[df_oa[[\"title\", \"abstract\", \"url\"]].duplicated()].index\n",
    "df_oa.drop(idx_duplicated, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d7e0cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23294, 8), (92525, 7))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_oa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a80c1fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113252, 8)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.concat([df, df_oa])\n",
    "\n",
    "df_full[\"year\"] = df_full[\"year\"].astype(str)\n",
    "df_full[\"published\"] = df_full[\"published\"].astype(str)\n",
    "df_full[\"authors\"] = df_full[\"authors\"].apply(lambda x: \", \".join(x))\n",
    "\n",
    "short_abstracts = df_full[df_full.abstract.apply(lambda x: len(x)) < 200].index\n",
    "df_full = df_full.drop(short_abstracts, axis=0)\n",
    "\n",
    "nan_titles = df_full[df_full.title.isna()].index\n",
    "df_full = df_full.drop(nan_titles, axis=0)\n",
    "\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda28e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_parquet(DATA_PATH+\"articles.parquet\", engine=\"pyarrow\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_full = pd.read_parquet(DATA_PATH+\"articles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef97030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def clean_whitespace(text: str) -> str:\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_latex(text: str) -> str:\n",
    "    text = re.sub(r\"\\$.*?\\$\", \" \", text) \n",
    "    text = re.sub(r\"\\\\[a-zA-Z]+\", \" \", text)\n",
    "    text = re.sub(r\"\\{.*?\\}\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def normalize_unicode(text: str) -> str:\n",
    "    return unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "def remove_urls(text: str) -> str:\n",
    "    return re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "\n",
    "def remove_special_chars(text: str) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9\\s.,;:!?()\\-']\", \"\", text)\n",
    "\n",
    "def remove_emails(text: str) -> str:\n",
    "    return re.sub(r\"\\S+@\\S+\", \"\", text)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = normalize_unicode(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_emails(text)\n",
    "    text = remove_latex(text)\n",
    "    text = remove_special_chars(text)\n",
    "    text = clean_whitespace(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4de53bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 3782/113252 [00:03<01:40, 1086.21it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Processing: 100%|██████████| 113252/113252 [01:44<00:00, 1080.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "def chunk_by_tokens(text, tokenizer, chunk_size=512, overlap=50):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    \n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        chunk = tokens[i:i+chunk_size]\n",
    "        chunk_text = tokenizer.decode(chunk)\n",
    "        chunks.append(chunk_text)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-small-en\")\n",
    "\n",
    "articles_chunks = []\n",
    "lenght = 500\n",
    "overlap = 100\n",
    "\n",
    "for n, row in tqdm(df_full.iterrows(), total=len(df_full), desc=\"Processing\"):\n",
    "    \"\"\"number_chunks = np.ceil(len(df_full.iloc[0].abstract) / lenght).astype('int')\n",
    "    for i in range(number_chunks):\n",
    "        index = i*lenght \n",
    "        abstract = row[\"abstract\"][index - overlap*(i > 0):]\n",
    "        \n",
    "        if len(abstract) >= lenght+overlap:\n",
    "            chunk = abstract[:lenght+(2*overlap)]\n",
    "        else:\n",
    "            chunk = abstract\"\"\"\n",
    "    text = \"Title: \"+ row[\"title\"] + \" - Abstract:\" + row[\"abstract\"]\n",
    "    text = clean_text(text)\n",
    "    chunks = chunk_by_tokens(text=text, tokenizer=tokenizer, chunk_size=512, overlap=50)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        articles_chunks.append({\"id\": n,\n",
    "                            \"title\": row.title,\n",
    "                            \"categories\": row.categories,\n",
    "                            \"abstract_chunk\": chunk,\n",
    "                            \"id_chunk\":i,\n",
    "                            \"authors\": row.authors,\n",
    "                            \"url\": row.url,\n",
    "                            \"published\": row.published,\n",
    "                            \"year\": row.year})\n",
    "        \n",
    "        #if len(row[\"abstract\"]) < (index+lenght+overlap):\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "83e749f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract_chunk</th>\n",
       "      <th>id_chunk</th>\n",
       "      <th>authors</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Structure-Attribute Transformations with Marko...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>title : structure - attribute transformations ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zhen Liu, Yongtao Zhang, Shaobo Ren, Yuxin You</td>\n",
       "      <td>http://arxiv.org/abs/2509.21059v1</td>\n",
       "      <td>2025-09-25 12:09:53+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MAIFormer: Multi-Agent Inverted Transformer fo...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>title : maiformer : multi - agent inverted tra...</td>\n",
       "      <td>0</td>\n",
       "      <td>Seokbin Yoon, Keumjin Lee</td>\n",
       "      <td>http://arxiv.org/abs/2509.21004v1</td>\n",
       "      <td>2025-09-25 10:59:29+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why Attention Fails: The Degeneration of Trans...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>title : why attention fails : the degeneration...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zida Liang, Jiayi Zhu, Weiqiang Sun</td>\n",
       "      <td>http://arxiv.org/abs/2509.20942v1</td>\n",
       "      <td>2025-09-25 09:25:51+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>FHRFormer: A Self-supervised Transformer Appro...</td>\n",
       "      <td>cs.LG, cs.AI, cs.CE, cs.CV</td>\n",
       "      <td>title : fhrformer : a self - supervised transf...</td>\n",
       "      <td>0</td>\n",
       "      <td>Kjersti Engan, Neel Kanwal, Anita Yeconia, Lad...</td>\n",
       "      <td>http://arxiv.org/abs/2509.20852v1</td>\n",
       "      <td>2025-09-25 07:40:21+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>T2I-Diff: fMRI Signal Generation via Time-Freq...</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>title : t2i - diff : fmri signal generation vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hwa Hui Tew, Junn Yong Loo, Yee-Fan Tan, Xinyu...</td>\n",
       "      <td>http://arxiv.org/abs/2509.20822v1</td>\n",
       "      <td>2025-09-25 07:08:19+00:00</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  Structure-Attribute Transformations with Marko...   \n",
       "1   1  MAIFormer: Multi-Agent Inverted Transformer fo...   \n",
       "2   2  Why Attention Fails: The Degeneration of Trans...   \n",
       "3   3  FHRFormer: A Self-supervised Transformer Appro...   \n",
       "4   4  T2I-Diff: fMRI Signal Generation via Time-Freq...   \n",
       "\n",
       "                   categories  \\\n",
       "0                       cs.LG   \n",
       "1                       cs.LG   \n",
       "2                       cs.LG   \n",
       "3  cs.LG, cs.AI, cs.CE, cs.CV   \n",
       "4                       cs.LG   \n",
       "\n",
       "                                      abstract_chunk  id_chunk  \\\n",
       "0  title : structure - attribute transformations ...         0   \n",
       "1  title : maiformer : multi - agent inverted tra...         0   \n",
       "2  title : why attention fails : the degeneration...         0   \n",
       "3  title : fhrformer : a self - supervised transf...         0   \n",
       "4  title : t2i - diff : fmri signal generation vi...         0   \n",
       "\n",
       "                                             authors  \\\n",
       "0     Zhen Liu, Yongtao Zhang, Shaobo Ren, Yuxin You   \n",
       "1                          Seokbin Yoon, Keumjin Lee   \n",
       "2                Zida Liang, Jiayi Zhu, Weiqiang Sun   \n",
       "3  Kjersti Engan, Neel Kanwal, Anita Yeconia, Lad...   \n",
       "4  Hwa Hui Tew, Junn Yong Loo, Yee-Fan Tan, Xinyu...   \n",
       "\n",
       "                                 url                  published  year  \n",
       "0  http://arxiv.org/abs/2509.21059v1  2025-09-25 12:09:53+00:00  2025  \n",
       "1  http://arxiv.org/abs/2509.21004v1  2025-09-25 10:59:29+00:00  2025  \n",
       "2  http://arxiv.org/abs/2509.20942v1  2025-09-25 09:25:51+00:00  2025  \n",
       "3  http://arxiv.org/abs/2509.20852v1  2025-09-25 07:40:21+00:00  2025  \n",
       "4  http://arxiv.org/abs/2509.20822v1  2025-09-25 07:08:19+00:00  2025  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = pd.DataFrame(data=articles_chunks)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "573fb426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121881, 9)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d494091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(DATA_PATH+\"articles_chunks.parquet\", engine=\"pyarrow\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9734206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook data_ingestion.ipynb to script\n",
      "[NbConvertApp] Writing 10113 bytes to data_ingestion.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script data_ingestion.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenvs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
